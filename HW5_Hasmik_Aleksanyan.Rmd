---
title: "Homework 5"
author: "Hasmik Aleksanyan"
date: "23, May 2020"
output:
   html_document:
    theme: "flatly"
    highlight: "zenburn"
    toc: TRUE
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(ggplot2, dplyr, MASS, caret, tidyr, class, DAAG, ROCR, FNN, rpart, rattle)

```


# Task 1: K-NN

Suppose you want to predict the class of new e-mails which make up 20% of your initial data using Kâˆ’NN. Compare the performance of the Logistic regression model (with all independent variables) and K-NN for classification using the data. Which one is better? Why? (Use the ROC curve to find the best cutoff value and cross-validation for choosing the value of k. Show both results graphically.)

Now, suppose you want to predict the total length of words in capitals based on their content and type for new e-mails which make up 25% of your initial data. Use two models: Linear Regression and K-NN. Compare the results. (Use RMSE, R2 to solve the task.)

## Solution 1
```{r}
dat <- spam7
```


```{r}
set.seed(777)
split <- dat$yesno %>% createDataPartition(p= 0.8, list = FALSE)
train <- dat[split, ]
test <- dat[-split, ]
```

```{r}
set.seed(777)
ctrl <- trainControl( method = 'cv', number = 10)
knn_c <- train ( yesno ~., data = dat, method ="knn",
               trControl = ctrl, preProcess = c("center", "scale"), tuneLength = 10)

plot(knn_c)

```

With the help of cross-validadion I have found the best k which is 5.

```{r}
knn <- knn(train = train[,-7], test = test[, -7], cl = train$yesno, k = 5 )

table(knn, test$yesno)
mean(knn == test$yesno)
 
table( test$yesno)/919

```

The Accuracy is 0.75 which is higher than non-information rate.

```{r}
Logit <- glm(yesno ~., family = binomial(link = "logit"), data = train)

test$yesno_hat <- predict(Logit, newdata = test, type = "response", list = F)
```

```{r}
pred = prediction(test$yesno_hat, test$yesno)

plot(performance(pred, "tpr", "tnr"),
  colorize=TRUE, print.cutoffs.at = seq(0,1,by=0.05), text.adj = c(-1,0.7))
```
With the help of ROC curve I have chosen that the best threshold is 0.35.

```{r}
confusionMatrix(as.factor(ifelse(test$yesno_hat >= 0.35, "y", "n")),test$yesno, positive = "y")
```
Again Accuracy is higher than No Information Rate. Also the accuracy of the logictic regression is higher than accuracy of the KNN classification. So that is why the logistic regression id better.

```{r}
data <- dat[, -7]
set.seed(123)
split <- sample(1: nrow(data), size = 3450)
train2 <- data[split, ]
test2 <- data[-split, ]

Linear <- lm(formula =crl.tot ~., data = train2)
predict <- predict(Linear, test2)

error<-predict-test2$crl.tot

RMSE<-sqrt(mean(error^2))
RMSE
```

```{r}
RMSEtrain <- NULL
RMSEtest <- NULL

for (i in 1:100) {
  trainknn <- knn.reg(train = train2[,-1],
                    test = train2[,-1], y = train2$crl.tot, k = i)
  testknn <- knn.reg(train = train2[,-1],
                    test = test2[,-1], y = train2$crl.tot, k = i)
  RMSEtrain[i] <- sqrt(mean((train2$crl.tot - trainknn$pred)^2))
  RMSEtest[i] <- sqrt(mean((test2$crl.tot - testknn$pred)^2))
}
```

```{r}
df <- data.frame(x = 1:50, train = RMSEtrain[1:50], test = RMSEtest[1:50])

ggplot( data = df, aes (x = x, y = train)) + 
  geom_point(color = "blue") + 
  labs( y = "Train RMSE" , x = "k", y = "Train RMSE")

ggplot( data = df, aes (x = x, y = test)) + 
  geom_point(color = "blue") + geom_line()+
  labs( y = "Test RMSE" , x = "k", y = "Test RMSE")
```
From the plots it is clear that the best k is 2.

```{r}
knn_reg <- knn.reg(train = train2[,-1],
                    test = test2[,-1], y = train2$crl.tot, k = 2)
  
RMSE <- sqrt(mean((test2$crl.tot - testknn$pred)^2))
RMSE


```
We can see that RMSE of KNN regression is smaller than RMSE of linear regression. So KNN regression is better.

# Task 2: DT
Refer to Problem 1 a. Use the full decision tree algorithm to solve the task. Show your tree and interpret the results.

How many observations have your smallest node? Set the minimum number of observations in any terminal node 25% of the number of your initial data. Show the tree. Why do we need the arguments minbucket and minsplit?

Make predictions based on both models.

Compare the models using the function confusionMatrix() and their results, ROC curve, and AUC. Which does perform better? Why?

## Solution 2

```{r}
set.seed(777)
split <- dat$yesno %>% createDataPartition(p= 0.8, list = FALSE)
train <- dat[split, ]
test <- dat[-split, ]

DT_model1 <- rpart(formula = yesno ~ .,
            data = train, method = "class")
DT_model1

```

```{r}
fancyRpartPlot(DT_model1)
```

It has 7 leaf nodes. In the smallest node there is 2% of the initial data.

```{r}
DT_pred1 <- predict(DT_model1, test, type = "class")
confusionMatrix(DT_pred1, test$yesno, positive = 'y')
```
The accuracy is higher than the no information rate.



```{r}
DT_model2 <- rpart(formula = yesno ~ .,
            data = train, method = "class" ,control = rpart.control(minsplit = nrow(train)*0.25, minbucket = nrow(train)*0.25))
fancyRpartPlot(DT_model2)
DT_pred2 <- predict(DT_model2, test, type = "class")
confusionMatrix(DT_pred2, test$yesno, positive = 'y')
```
Minsplit is the minimum number of observations that must exist in a node in order for a split to be attempted.
Minbucket is the minimum number of observations in any terminal <leaf> node. In the second model the accuracy is smaller than in the first model.

```{r}
DT_pred_prob1 <- predict(DT_model1, test, type = "prob")
pred1 = prediction(DT_pred_prob1[,2], test$yesno)
plot(performance(pred1, "tpr", "fpr"))
```

```{r}
DT_pred_prob2 <- predict(DT_model2, test, type = "prob")
pred2 = prediction(DT_pred_prob2[,2], test$yesno)
plot(performance(pred2, "tpr", "fpr"))

```

```{r}
(AUC_1 <- performance(pred1, "auc")@y.values)
(AUC_2 <- performance(pred2, "auc")@y.values)
```
In the first model area under ROC curve is bigger than in the second model. That is why the first model is better.



# Task 3: DT2
Consider the following training examples for a binary classification problem:

a1	a2	Class
T	T	0
T	T	0
T	F	1
F	F	0
F	T	1
F	T	1
F	F	1
T	F	0
F	T	1
What is the best split between a1 and a2 according to the classification error rate? Show all calculations in R.

What is the best split between a1 and a2 according to the Gini index? Show all calculations in R.

Which attribute would the decision tree algorithm choose? Why?



## Solution 3

```{r}
a1 <- c('T','T','T','F','F','F','F','T','F')
a2 <- c('T','T','F','F','T','T','F','F','T')
class <- c('0','0','1','0','1','1','1','0','1')
table(a1,class)
table(a2,class)
dat <- data.frame(a1,a2,class)

data.frame(dat %>% 
            group_by(a1,class) %>%
            summarise(number_of_obs = n()))


data.frame(dat %>% 
            group_by(a2,class) %>%
            summarise(number_of_obs = n()))
```

```{r}
a1_Gini_F = 1- (4/5)^2 - (1/5)^2
a1_Gini_T = 1 - (3/4)^2 - (1/4)^2
(a1_Weighted_Gini = a1_Gini_F*5/9 + a1_Gini_T*4/9)

a2_Gini_F = 1- (2/4)^2 - (2/4)^2
a2_Gini_T = 1 - (2/5)^2 - (3/5)^2
(a2_Weighted_Gini = a2_Gini_F*4/9 + a2_Gini_T*5/9)

```

a1 split has smaller Gini index than a2. The best split between a1 and a2 is a1.

```{r}
a1_Error_F = 1- max(1/5,4/5)
a1_Error_T = 1 - max(3/4,1/4)
(a1_Weighted_Error = a1_Error_F*5/9 + a1_Error_T*4/9)

a2_Error_F = 1 - max(2/4,2/4)
a2_Error_T = 1 - max(2/5,3/5)
(a2_Weighted_Error = a2_Error_F*5/9 + a2_Error_T*4/9)

```
a1 split has smaller error rate than a2. The best split between a1 and a2 is a1.

Decision tree algorithm  would choose a1 attribute. Cause in CART it uses Gini index.


# Questions

1.What are the differences between Logit and K-NN Classification? List at least 3 meaningful differences.

2.When does Linear Regression outperform the K-NN Regression?

3.Bring a (graphical) example in R of a data set that cannot be partitioned effectively by a DT algorithm using test conditions involving only a single attribute. How can you overcome this difficulty?

4.What is the difference between regression and classification tree (in terms of the loss function, prediction method, and type of dependent variable)?

5.How much time did it take to accomplish the HW? What is the/your best way to overcome procrastination?

## Answers

1.Logit - probability based, parametric, linear solutions
  KNN - distance based,  non-parametric, non-linear solutions


2. If the true relationship is linear then Linear Regression outperform the K-NN Regression.

3. 
```{r}

x <- runif(1000,0,1)
y <-runif(1000, 0,1) 
dt <- data.frame(x,y)

dt$class <- ifelse(dt$y < (1-dt$x), "yes", "no")
ggplot( data = dt, aes (x = x, y = y, color = class)) + 
  geom_point() 

```
An oblique decision tree can be used , beacause it allows test conditions that involve more than one attribute. 

4.Regression tree - dependent variable is numeric, it uses RSS for splitting, in the node it shows mean value of observations, so the prediction takes the mean value of the node for the new data
  Classification tree - dependent variable is categorical, it uses GINI index for splitting, in the node it shows proportion of observations in the node, so for the new data the prediction takes that category which proportion in the node is the most 

5. 2 days. I dont know, maybe more practising :))



